{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch.nn import init\n",
    "import numpy as np\n",
    "import sys\n",
    "sys.path.append(\"..\")\n",
    "import d2lzh_pytorch as d2l\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#获取和读取数据\n",
    "batch_size = 256\n",
    "train_iter,test_iter = d2l.load_data_fashion_mnist(batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], requires_grad=True)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#定义和初始化模型\n",
    "num_inputs = 784\n",
    "num_outputs = 10\n",
    "\n",
    "\n",
    "class FlattenLayer(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(FlattenLayer,self).__init__()\n",
    "    def forward(self,x):\n",
    "        return x.view(x.shape[0],-1)#256*1*28*28 ——> 256 * 784\n",
    "from collections import OrderedDict\n",
    "net = nn.Sequential(\n",
    "        OrderedDict([\n",
    "            ('flatten',FlattenLayer()),\n",
    "            ('linear',nn.Linear(num_inputs,num_outputs))\n",
    "        ])\n",
    ")\n",
    "\n",
    "init.normal_(net.linear.weight,mean=0,std=0.01)\n",
    "init.constant_(net.linear.bias,val=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#SOFTMAX和交叉熵损失函数\n",
    "loss = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#定义优化算法\n",
    "optimizer = torch.optim.SGD(net.parameters(),lr=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 1, loss 0.0031, train acc 0.751, test acc 0.789\n",
      "epoch 2, loss 0.0022, train acc 0.813, test acc 0.808\n",
      "epoch 3, loss 0.0021, train acc 0.825, test acc 0.821\n",
      "epoch 4, loss 0.0020, train acc 0.832, test acc 0.824\n",
      "epoch 5, loss 0.0019, train acc 0.836, test acc 0.826\n"
     ]
    }
   ],
   "source": [
    "#训练模型\n",
    "num_epochs = 5\n",
    "d2l.train_ch3(net,train_iter,test_iter,loss,num_epochs,\n",
    "             batch_size,None,None,optimizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
